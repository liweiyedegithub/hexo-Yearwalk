---
title: 谷歌新闻聚合+飞书通知
date: 2026-1-14 10:25:01
tags: 
  - News
  - RSS
top: false
categories: 
  - 飞书机器人
img: /medias/featureimages/11.jpg

---
下面是一份“**闭环、可扩展、可运维**”的设计说明（Markdown）。不含代码，只讲每一步做什么、为什么做、和哪些模块有关联、以及关键的边界/验收标准。

---

# GoogleNews → 翻译 → 入库 → 飞书分发：闭环系统设计说明

> 目标：构建一套可长期运行的“新闻简报系统”，支持配置驱动、可扩展多源、可去重、可翻译、可分发、可定时、可观测、可恢复。

---

## 0. 系统总体目标与约束

### 0.1 总体目标

1. **自动化**：按时间计划自动采集 → 翻译 → 发送飞书，形成每日/每小时简报。
2. **可配置**：所有可变内容（源、关键词、窗口、频率、重试、代理、输出格式）都在 `config.json`。
3. **去重与幂等**：同一条新闻不会重复入库、不会重复发送。
4. **可运维**：日志可追踪、失败可重试、能定位问题、可回滚/重发。
5. **可扩展**：未来能增加新的 RSS/站点/API 采集源，不破坏现有结构。

### 0.2 关键约束/现实问题

* Linux cron 环境与交互式 shell 不同：PATH、代理、虚拟环境都可能不一致。
* VPN 代理往往只对浏览器生效：脚本需要显式代理环境变量或 proxies 配置。
* 新闻源质量不稳定：可能超时、被墙、结构变化、返回内容异常。
* 翻译 API 有配额/错误码/识别失败：必须重试与兜底记录。

---

## 1. 架构分层与模块划分（4 个脚本 + 1 个配置 + 1 个数据库）

### 1.1 模块列表

* `config.json`：全局配置（单一真相来源）
* `news_db.py`：数据库管理（初始化、查询、统计、重置标记、清理）
* `collector.py`：采集模块（从新闻源抓取→解析→入库）
* `translator.py`：翻译模块（从库读未发送→翻译→回写中文字段）
* `feishu_sender.py`：分发模块（从库读未发送→发送飞书→打标）
* `run_job.sh`：运维入口（统一日志、时间戳、目录切换、代理、python 解释器）
* `*.log`：可观测输出（每次执行都可追溯）

### 1.2 为什么要拆成 4 步而不是一个脚本完成

1. **失败隔离**：采集失败不影响翻译/发送；翻译失败不影响入库。
2. **可重试**：每一步都可单独重跑，不会重复入库/重复发送。
3. **可替换**：未来翻译从腾讯云换成其他服务，只改 translator。
4. **可运维**：日志更清晰，定位故障更快。

---

## 2. 配置中心设计（config.json）

### 2.1 配置原则

* **配置驱动**：脚本逻辑尽量抽象化，所有策略通过配置控制。
* **默认可用**：执行 `python3 xxx.py` 或 `python3 xxx.py start` 能按配置直接跑。
* **敏感信息隔离**：密钥/Token 建议放环境变量或单独 secrets 文件（至少避免日志打印）。

### 2.2 配置应覆盖的内容

* DB：路径、表名、SQLite pragmas
* Collect：启用的源列表、关键词、recent_hours、top_n、网络超时、重试策略、代理
* Translate：目标语言（固定中文）、recent_hours、重试次数、腾讯云密钥与区域、失败兜底策略
* Send：飞书 webhook、是否签名、发送窗口、发送上限、失败重试
* Logging：是否打印 URL、打印条数限制、输出格式开关（人类可读/JSON 可读）

### 2.3 配置关联关系

* collect/translate/send **必须共用同一个 DB 配置**（db.path + db.table 一致）
* collect 插入的数据字段必须满足 translator 读取字段（title/content）
* translator 写回字段必须满足 sender 的优先读取（title_zh/content_zh）

---

## 3. 数据库设计（SQLite）与数据生命周期

### 3.1 表结构（核心字段）

最小必需字段（你的需求）：

* `id`：自增唯一主键
* `created_at`：入库时间（系统时间）
* `title_original` / `title_zh`
* `content_original` / `content_zh`
* `url`：原文链接（用于去重/溯源）
* `source`：新闻来源（媒体名）
* `published_at`：新闻发布时间（源端）
* `keyword`：命中的搜索关键字（用于分组统计与订阅维度）
* `feishu_sent`：是否已发送（0/1）
* `feishu_sent_at`：发送时间（系统时间）
* `extra1/extra2/extra3`：预留字段（未来扩展，如作者、地区、情感分等）

### 3.2 去重与幂等（关键）

**唯一键建议：`url`**

* 采集入库使用 `INSERT OR IGNORE` 或等效逻辑。
* 作用：脚本重复跑不会插重复数据，保障幂等。

补充建议（更抗变化）：

* 如果源 URL 不稳定，可考虑 `unique(url)` + `unique(url, published_at)` 或添加 `guid` 字段。

### 3.3 数据流状态机（闭环的核心）

每条新闻在库中会经历以下状态：

1. `已采集`：有 original 字段、`feishu_sent=0`
2. `已翻译`：`title_zh/content_zh` 写入（即使失败也写入错误文本，便于追踪）
3. `已发送`：发送成功后 `feishu_sent=1`，写入 `feishu_sent_at`

这是闭环的“真相”，所有脚本都围绕这个状态机工作。

### 3.4 DB 管理工具（news_db.py）的定位

数据库脚本提供“运维能力”，支持你提的功能：

* recent：查询最近 X 行（按 created_at 倒序）
* reset-sent：最近 X 行标记为未发送（用于重发）
* delete：删除最近 X 行（清理错误数据）
* stats：查看文件大小/行数（人类可读 + json）
* group-by-keyword：按 keyword 分组统计并倒序排列

这些功能让系统经得起长期运行、错误恢复、以及运营分析。

---

## 4. 采集模块设计（collector）

### 4.1 目标与边界

目标：从配置指定的“新闻源”抓取内容，并按关键词形成“近24小时 Top10”。

边界：

* collector 不负责翻译，不负责发送飞书
* collector 只做：拉取 → 解析 → 规范化 → 入库 → 打印总结

### 4.2 采集策略（按你最终需求）

* **只采集“包含关键字”的新闻 Top10**
* 示例：`Trump` 最近 24 小时活动/新闻 Top10
* 实现上采用 Google News Search RSS，并附 `when:1d` 或等效时间过滤

### 4.3 健壮性加固点

* 网络：超时、重试、退避
* 代理：显式支持 http/https proxies（尤其 cron 环境）
* 解析：XML/HTML 实体处理，字段缺失兜底
* 入库：字段规范化（空字符串处理），失败不中断（逐条容错）
* 打印：人类可读格式：标题/发布时间/来源/关键词/链接，最后汇总统计

### 4.4 输出验收标准

* dry-run：能看到 10 条结构化打印 + 汇总
* 入库后：DB 中新增对应 rows（或重复被忽略，仍应打印 inserted/ignored）
* 同一个关键词重复运行：不会重复入库（幂等）

---

## 5. 翻译模块设计（translator）

### 5.1 目标与边界

目标：对“最近 N 小时、未发送”的新闻做翻译，并回写中文字段。

边界：

* translator 不采集，不发送飞书
* 只处理数据库行，结果写回 DB

### 5.2 翻译策略（你的要求）

* 源语言自动识别 → 目标中文
* 失败重试 3 次（配置化）
* 如果都失败：把最后一次失败信息写入 `title_zh` 或 `content_zh`（可观测、可排障）

### 5.3 关键设计点

* **过滤范围**：只处理 `feishu_sent=0` 且 `created_at >= now - recent_hours`
* **幂等性**：可以选择仅翻译 `title_zh/content_zh 为空` 的记录，避免重复翻译扣费
* **长文本策略**：正文可能过长，需要分段/截断/合并（视腾讯云接口限制）
* **日志**：记录翻译成功/失败、错误码、处理条数

### 5.4 输出验收标准

* dry-run 能看到翻译结果对比
* 正式运行后 DB 的 `title_zh/content_zh` 更新
* 遇到识别失败也能写入错误信息（不“静默失败”）

---

## 6. 飞书发送模块设计（feishu_sender）

### 6.1 目标与边界

目标：把未发送新闻按格式推送到飞书群机器人，并把 DB 打标为已发送。

边界：

* sender 不采集、不翻译
* sender 只依赖 DB 作为消息源

### 6.2 发送策略

* 选择 `feishu_sent=0` 且 `created_at` 在最近窗口内的记录
* 每次最多发送 limit 条（配置化，防止刷屏）
* 文本优先级：中文字段优先，中文为空才用原文

### 6.3 消息格式（你的要求 + 最佳实践）

* 关键字：XXX
* 标题：XXX
* 正文：XXX
* 发布时间：XXX（自动转换成中文时间，台北/北京时间）

补充建议：

* 正文可限制最大长度，过长截断并附“原文链接”
* 链接必带，方便溯源与点击

### 6.4 幂等与一致性（核心）

* 发送成功后立刻更新：

  * `feishu_sent=1`
  * `feishu_sent_at=当前时间`
* 如果发送失败：

  * 不打标，保留 `feishu_sent=0`，下一轮继续重试
* 若你需要“手动重发”：

  * 通过 `news_db.py reset-sent --limit X` 把标记改回 0

### 6.5 输出验收标准

* dry-run：打印“将发送哪些内容”
* 正式运行：飞书收到消息；DB 的 sent 字段更新
* 重跑不重复：已发送的不会再次发送

---

## 7. 定时任务与运维（cron + run_job.sh）

### 7.1 定时策略（你的要求）

* 采集：每天 07:00
* 翻译：每小时 10 分
* 发送：每小时 20 分

这形成一个合理流水线：先产生数据 → 10 分翻译 → 20 分推送。

### 7.2 为什么需要 run_job.sh

cron 环境非常简陋，容易出现：

* 用错 python（系统 python vs venv python）
* 找不到模块（依赖没加载）
* 工作目录不对（相对路径失效）
* 代理不生效（VPN 仅浏览器可用）

run_job.sh 的作用：

* 固定工作目录
* 固定 python 解释器（优先 venv）
* 每次执行前输出系统时间（RUN_AT）
* 统一日志追加到同目录
* 统一注入代理环境变量（如需要）

### 7.3 日志策略

* collector.log / translator.log / feishu_sender.log 分离
* 每次执行写入：

  * 当前系统时间
  * 执行命令
  * 标准输出与错误输出
* 建议增加日志轮转（按月/按大小）

### 7.4 验收与监控

最小验收：

* 观察日志是否按时增加
* 采集/翻译/发送每步都有统计行
* 出错时日志包含堆栈与错误信息

扩展监控（可选）：

* 每天汇总 “新增/翻译/发送” 数量
* 发送失败次数告警（飞书自发一条“系统异常”消息）

---

## 8. 网络与代理（VPN 场景的关键设计）

### 8.1 为什么“开了 VPN 仍访问不到”

因为常见 VPN/代理只对浏览器生效，脚本与 cron 不会自动走代理。

### 8.2 解决方案

* 在 run_job.sh 中 export `http_proxy/https_proxy`
* 或在 config.json 中提供 proxies，脚本显式使用
* 尽量使用相同用户运行 cron（代理进程属于哪个用户，就用哪个用户跑任务）

### 8.3 验收方法

* curl 直连失败但 curl 走代理成功 → 说明必须给脚本加代理
* 脚本 fetch 成功 → 网络层问题解决

---

## 9. 可靠性与可恢复（经得起考验）

### 9.1 关键可靠性机制

* 重试：采集/翻译/发送都应有重试（配置化）
* 幂等：入库去重 + 发送打标
* 失败可见：错误写日志；翻译失败写入字段（可追踪）
* 单点故障隔离：每个模块失败不影响其它模块运行

### 9.2 常见故障与恢复手册

* **采集失败**：检查代理、DNS、超时 → 重跑 collector
* **翻译失败**：检查腾讯云密钥/配额/语种识别 → 重跑 translator
* **发送失败**：检查 webhook/签名/网络 → 重跑 sender
* **要重发最近 50 条**：news_db.py reset-sent --limit 50 → 再跑 sender

---

## 10. 里程碑与交付物（你当前已完成到哪）

你这套系统按产品交付可分 4 个里程碑：

1. **数据库层（M1）**：表结构 + 管理工具（init/stats/recent/reset/delete/group）
2. **翻译层（M2）**：按窗口读取 + 重试 + 写回 + 失败兜底
3. **采集层（M3）**：按关键词近24小时 Top10 + 入库 + 可读输出 + 扩展源架构
4. **分发层（M4）**：飞书推送 + 打标 + 定时任务 + 日志 + 代理可用

你现在已经实现 M1~M4 的闭环，系统已具备上线运行条件。

---

# 结语：系统为什么“闭环”

闭环的本质在于数据库状态机：

* collector 负责生产数据（进入库）
* translator 负责增强数据（中文字段补齐）
* feishu_sender 负责消费数据（发送并打标）
* news_db.py 负责运维与恢复（查询/统计/重置/清理）
* cron + run_job.sh 负责自动化运行与可观测

只要这条链路不断，系统就能长期稳定运行、可扩展、可诊断、可恢复。

---

如果你希望这份文档“更像产品PRD/技术方案”，我可以再补两块：

1. **字段字典（Data Dictionary）**：每个字段的类型/约束/示例
2. **验收用例（Test Cases）**：每个模块 5~10 条可执行验收清单（上线前必跑）
